# Session 1

---

## Deeper Understanding of LLMs

- Learned that LLMs are probabilistic models.
- Understood tokenization and vector representation.
- Gained clarity on self-attention mechanism.

---

## Importance of Context

- Context window limits model memory.
- Hallucination often results from context loss.
- RAG helps overcome this limitation.

---

## Practical Use of Embeddings

- Learned how embeddings enable semantic similarity.
- Understood how vector databases scale large datasets.
- Realized importance in search engines and AI assistants.

---

## RAG & Hybrid Search

- Learned how retrieval improves answer accuracy.
- Understood combining keyword + vector search.
- Recognized enterprise relevance.

---

## Multimodal AI Awareness

- Learned how images and audio are processed.
- Understood Base64 encoding necessity.
- Realized real-world applications in surveillance and safety.

---

## Prompt Engineering Insight

Major takeaway:
Prompt quality directly affects output quality.

Understood:
- Structured prompting
- Schema-based output
- Need for documentation
- Model-specific tuning

---

## Structured Extraction Skills

- Learned how to convert unstructured text into JSON.
- Understood schema enforcement.
- Recognized commercial applications in invoice automation.

---

## Function Calling Understanding

- Learned how LLMs extract parameters.
- Understood backend function triggering.
- Realized how intelligent assistants are built.

---

## Production-Level Thinking

- Learned importance of:
  - Model evaluation
  - Cost comparison
  - Regression testing
- Understood how commercial AI systems are maintained.

---

## Overall Growth

Module 3 expanded my understanding from:

"Using AI APIs"  
to  
"Designing scalable AI systems".

I now understand how to architect intelligent, production-ready AI applications.
